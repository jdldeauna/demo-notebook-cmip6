{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrating updated functionality for xgcm - [SIParCS 2021](https://www2.cisl.ucar.edu/siparcs-2021-projects#8)\n",
    "\n",
    "Grid-aware operations such as average, integrate and cumulative integration rely on user-provided [grid metrics](https://xgcm.readthedocs.io/en/latest/grid_metrics.html). This notebook demonstrates the methods `interp_like()`, `get_metric()`, and `set_metrics()` which makes working with metrics easier, better, faster, and shorter when processing ocean models. The main objective of this notebook is to calculate and plot the time series of area-averaged temperature and zonal velocity from an Earth System Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the packages we need for this example. To run a piece of code, click on the cell and hit `Shift` + `Enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import matplotlib as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import cftime\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/xgcm/xgcm.git\n",
      "  Cloning https://github.com/xgcm/xgcm.git to /private/var/folders/p2/czdpkv7x0q3gfchwp2nw54g40000gn/T/pip-req-build-nd40xh03\n",
      "  Running command git clone -q https://github.com/xgcm/xgcm.git /private/var/folders/p2/czdpkv7x0q3gfchwp2nw54g40000gn/T/pip-req-build-nd40xh03\n",
      "  Running command git submodule update --init --recursive -q\n",
      "Requirement already satisfied: xarray>=0.14.1 in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from xgcm==0.5.3.dev24+g6e68f71) (0.17.0)\n",
      "Requirement already satisfied: dask in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from xgcm==0.5.3.dev24+g6e68f71) (2021.4.0)\n",
      "Requirement already satisfied: numpy in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from xgcm==0.5.3.dev24+g6e68f71) (1.20.2)\n",
      "Requirement already satisfied: future in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from xgcm==0.5.3.dev24+g6e68f71) (0.18.2)\n",
      "Requirement already satisfied: docrep<=0.2.7 in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from xgcm==0.5.3.dev24+g6e68f71) (0.2.7)\n",
      "Requirement already satisfied: six in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from docrep<=0.2.7->xgcm==0.5.3.dev24+g6e68f71) (1.16.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from xarray>=0.14.1->xgcm==0.5.3.dev24+g6e68f71) (1.3.0)\n",
      "Requirement already satisfied: setuptools>=40.4 in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from xarray>=0.14.1->xgcm==0.5.3.dev24+g6e68f71) (49.6.0.post20210108)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from pandas>=0.25->xarray>=0.14.1->xgcm==0.5.3.dev24+g6e68f71) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from pandas>=0.25->xarray>=0.14.1->xgcm==0.5.3.dev24+g6e68f71) (2021.1)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from dask->xgcm==0.5.3.dev24+g6e68f71) (0.11.1)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from dask->xgcm==0.5.3.dev24+g6e68f71) (1.6.0)\n",
      "Requirement already satisfied: pyyaml in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from dask->xgcm==0.5.3.dev24+g6e68f71) (5.4.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from dask->xgcm==0.5.3.dev24+g6e68f71) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from dask->xgcm==0.5.3.dev24+g6e68f71) (2021.7.0)\n",
      "Requirement already satisfied: locket in /Users/odyssey/miniconda3/envs/test_env_xgcm/lib/python3.8/site-packages (from partd>=0.3.10->dask->xgcm==0.5.3.dev24+g6e68f71) (0.2.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.5.3.dev24+g6e68f71'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python -m pip install git+https://github.com/xgcm/xgcm.git\n",
    "import xgcm\n",
    "xgcm.__version__\n",
    "# make sure it's above 0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dask_gateway'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0feafee7cd34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdask_gateway\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGatewayCluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGatewayCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dask_gateway'"
     ]
    }
   ],
   "source": [
    "from dask_gateway import GatewayCluster\n",
    "cluster = GatewayCluster()\n",
    "cluster.adapt(minimum=2, maximum=10) \n",
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we download temperature (`thetao`), zonal velocity (`uo`) and horizontal area (`areacello`) for the CNRM-ESM2-1 model, just one example of an [Earth System Model](https://pcmdi.llnl.gov/CMIP6/ArchiveStatistics/esgf_data_holdings/). ESMs are global, 4-dimensional, coupled ocean-atmosphere-biogeochemical models commonly used to evaluate the effects of increased atmospheric carbon dioxide concentrations on planetary processes. Check out [this page](https://www.carbonbrief.org/cmip6-the-next-generation-of-climate-models-explained) for further information. In this example, we are using historical data from 1850 to 2014, but we can change the code to download [model results from 2015 to 2100](https://www.carbonbrief.org/explainer-how-shared-socioeconomic-pathways-explore-future-climate-change) under high to low climate change mitigation scenarios, so feel free to explore! The latest version of these datasets are under CMIP6 and are hosted in the cloud by the [Pangeo project](https://pangeo.io/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = intake.open_esm_datastore(\"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\")\n",
    "cat = col.search(\n",
    "    source_id = 'CNRM-ESM2-1', # use a different source ID if you want to try other models\n",
    "    member_id = 'r1i1p1f2', # common values are r1i1p1f1 or r1i1p1f2\n",
    "    experiment_id = 'historical', # other possible inputs: ssp126, ssp370, and ssp585 \n",
    "    variable_id= ['thetao','uo','areacello'],\n",
    "    grid_label = 'gn', # common values are gn or gr \n",
    "    \n",
    ")\n",
    "ddict = cat.to_dataset_dict(zarr_kwargs={'consolidated':True, 'use_cftime':True}, aggregate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manually extract thetao, uo and areacello using the `ddict.keys` info above, so we can do subsetting and renaming before we save the datasets into one array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetao = ddict['CMIP.CNRM-CERFACS.CNRM-ESM2-1.historical.r1i1p1f2.Omon.thetao.gn.gs://cmip6/CMIP6/CMIP/CNRM-CERFACS/CNRM-ESM2-1/historical/r1i1p1f2/Omon/thetao/gn/v20181206/.nan.20181206'].thetao\n",
    "uo = ddict['CMIP.CNRM-CERFACS.CNRM-ESM2-1.historical.r1i1p1f2.Omon.uo.gn.gs://cmip6/CMIP6/CMIP/CNRM-CERFACS/CNRM-ESM2-1/historical/r1i1p1f2/Omon/uo/gn/v20181206/.nan.20181206'].uo\n",
    "areacello = ddict['CMIP.CNRM-CERFACS.CNRM-ESM2-1.historical.r1i1p1f2.Ofx.areacello.gn.gs://cmip6/CMIP6/CMIP/CNRM-CERFACS/CNRM-ESM2-1/historical/r1i1p1f2/Ofx/areacello/gn/v20181206/.nan.20181206'].areacello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the uo grid is shifted to the right along the x-axis (`lon`) compared to thetao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "diff = uo.lon-thetao.lon\n",
    "diff.plot(vmin=-2,vmax=2)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign areacello as a coordinate for thetao since they are on a similar grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetao = thetao.assign_coords(areacello=areacello.reset_coords(drop=True).fillna(0)) # drop areacello lat/lon coordinates, fill missing values with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subset our preferred patch of ocean from the global datasets. For now the domain limits are set to the California Current, but you can adjust lat_north, lat_south, lon_west, and lon_east to your liking. As you change these values, make sure `subset_thetao` and `subset_uo` are the same size (see cell below). To do that, we recommend changing the longitude/latitude values incrementally by 0.25 deg until you get a satisfactory domain size.\n",
    "\n",
    "Additionally, CNRM-ESM2-1 uses negative values east of the IDL (i.e., 130 W is -130), and this can vary per model so if you change `source_id` in the beginning, make sure you know which longitude convention that model uses. We also do surface plots to make sure we did the subsetting correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_north = 50\n",
    "lat_south = 25\n",
    "lon_west = -130\n",
    "lon_east = -110.75\n",
    "\n",
    "subset_thetao = thetao.where((thetao.lat > lat_south) & (thetao.lat < lat_north) & (thetao.lon > lon_west) & (thetao.lon < lon_east), drop=True)\n",
    "subset_uo = uo.where((uo.lat > lat_south) & (uo.lat < lat_north) & (uo.lon > lon_west) & (uo.lon < lon_east), drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you adjusted that lat/lon limits in any way, replace `subset_thetao` in the cell below with `subset_uo` to double-check if subset_thetao and subset_uo are the same size (e.g., the 'x' and 'y' values for variables such as 'lat' and 'lon' should be equal, and for this example `y: 38`, `x: 20`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_thetao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the zonal velocity subset (to make sure we subset properly!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "ax = plt.axes(projection=ccrs.Mercator())\n",
    "subset_uo.isel(lev=0,time=0).squeeze().plot.pcolormesh(ax=ax, x='lon', y='lat', transform=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "coast_10m = cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='w', facecolor='0.8')\n",
    "ax.add_feature(coast_10m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the temperature subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "subset_thetao.isel(lev=0,time=0).squeeze().plot.pcolormesh(ax=ax, x='lon', y='lat', transform=ccrs.PlateCarree())\n",
    "coast_10m = cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='w', facecolor='0.8')\n",
    "ax.add_feature(coast_10m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `uo` is shifted to the right compared to `thetao`, we rename its coordinates (such that `thetao` coordinates will be referred to as 'x', 'lon', and 'lat')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_uo = subset_uo.rename({'x':'x_c','lon':'lon_u', 'lat':'lat_u'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After renaming, we can merge the datasets into one DataArray using `xarray.merge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_subset = xr.merge([subset_thetao, subset_uo], compat='override')\n",
    "ds_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look more closely, the dimensions of temperature and zonal velocity are now different. Take note that the metrics used for each variable when doing grid-aware operations such as averaging, should match. This means we can use `areacello` for temperature, but what about for the zonal velocity? (Stay tuned!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_subset.thetao.dims)\n",
    "print(ds_subset.areacello.dims)\n",
    "print(ds_subset.uo.dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a time series of average surface temperature data from CNRM-ESM2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating average temperature over time is straightforward since we have the metric `areacello` with the right axes `(\"X\",\"Y\")` and dimensions `(x, y)`. The xgcm package uses a `Grid` class, and so first we create a `grid` object which contains our dataset `ds_subset` and assign parameters such as metrics. Then we perform a grid-weighted `average` based on this `grid` object, and plot the result as a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgcm import Grid\n",
    "grid = Grid(\n",
    "    ds_subset,\n",
    "    coords={\n",
    "        'X':{'center':'x', 'right':'x_c'},\n",
    "        'Y':{'center':'y', 'right':'y_c'},\n",
    "        'Z':{'center':'lev'},\n",
    "    },\n",
    "    periodic=False,\n",
    "    boundary='extend',\n",
    "    metrics={('X','Y'): 'areacello'}\n",
    ")\n",
    "grid._metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can change the depth layer (take note that this is an index, so 0 in this case translates to 0.50576 meters) \n",
    "# and time series bounds (historical data is monthly data from 1860 to 2014, while ssp data is from 2015 to 2100)\n",
    "# doing the plots may take a few minutes, depending on the extent of the time series you want to plot\n",
    "\n",
    "lev_layer = 0\n",
    "time_start='2012-01-01'\n",
    "time_end='2014-12-31'\n",
    "\n",
    "mean_sst = grid.average(ds_subset.thetao.isel(lev=lev_layer).sel(time=slice(time_start,time_end)).squeeze(),['X','Y'])\n",
    "mean_sst.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a time series of average surface zonal velocity data from CNRM-ESM2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous versions of `xgcm`, trying to plot u-velocity the way we did with temperature would have failed, because we did not provide metrics at the right dimensions. (Recall that along the x-axis, areacello is at 'x', while uo is at 'x_c')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![xgcm-version](xgcm-version.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![average-uo.png](average-uo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do it successfully, we would have had to do it the long way: create a `grid` object with `areacello` as a metric, interpolate the area metric to the u-velocity grid (`areacello_uo`), create another grid object with updated metrics, then calculate the `average`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgcm import Grid\n",
    "\n",
    "# Step 1: Create a grid object with the available metric\n",
    "grid = Grid(\n",
    "    ds_subset,\n",
    "    coords={\n",
    "        'X':{'center':'x', 'right':'x_c'},\n",
    "        'Y':{'center':'y', 'right':'y_c'},\n",
    "        'Z':{'center':'lev'},\n",
    "    },\n",
    "    periodic=False,\n",
    "    boundary='extend',\n",
    "    metrics={('X','Y'): 'areacello'}\n",
    ")\n",
    "\n",
    "# Step 2: Interpolate the available metric to the desired variable grid and assign it as a coordinate\n",
    "areacello_uo = grid.interp(ds_subset.areacello,(\"X\")) \n",
    "ds_subset = ds_subset.assign_coords(areacello_uo=areacello_uo.reset_coords(drop=True).fillna(0))\n",
    "\n",
    "# Step 3: Create a new grid object \n",
    "grid_demo = Grid(\n",
    "    ds_subset,\n",
    "    coords={\n",
    "        'X':{'center':'x', 'right':'x_c'},\n",
    "        'Y':{'center':'y', 'right':'y_c'},\n",
    "        'Z':{'center':'lev'},\n",
    "    },\n",
    "    periodic=False,\n",
    "    boundary='extend',\n",
    "    metrics={('X','Y'): 'areacello_uo'}\n",
    ")\n",
    "\n",
    "# Step 4: Calculate the average and plot the time series\n",
    "lev_layer=0\n",
    "time_start='2012-01-01'\n",
    "time_end='2014-12-31'\n",
    "\n",
    "mean_uo_demo = grid_demo.average(ds_subset.uo.isel(lev=lev_layer).sel(time=slice(time_start,time_end)).squeeze(),['X','Y'])\n",
    "mean_uo_demo.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we can do it the short way! With the addition of `interp_like`, and updated versions of `get_metric` and `set_metrics`, we can use the exact same lines of code as we did for calculating the temperature time series (do it in 1 step vs 4 steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev_layer=0\n",
    "time_start='2012-01-01'\n",
    "time_end='2014-12-31'\n",
    "\n",
    "mean_uo = grid.average(ds_subset.uo.isel(lev=lev_layer).sel(time=slice(time_start,time_end)).squeeze(),['X','Y'])\n",
    "mean_uo.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrating updated functionality for the xgcm package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at how and why this worked. Since our available horizontal area metric (areacello) is in temperature dimensions, to get the metric for the u-velocity grid, we need to interpolate areacello to u-velocity dimensions. We can use the `interp_like` method or `get_metric` (which uses `interp_like` \"under the hood\"). For this example, the inputs for `interp_like` are the available metric (\"ds_subset.areacello\") and the array you need a metric for (\"ds_subset.uo\"). The inputs for `get_metric` are the array you need a metric for (\"ds_subset.uo\") and the axes to interpolate it to ((\"X\",\"Y\")). The method will use the metric available on the (\"X\",\"Y\") axis already assigned to the grid object (\"areacello\") for the interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areacello_uo = grid.interp_like(ds_subset.areacello,ds_subset.uo)\n",
    "areacello_uo_getmetric = grid.get_metric(ds_subset.uo,(\"X\",\"Y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-check if the interpolated metrics are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_metric = xr.testing.assert_equal(areacello_uo,areacello_uo_getmetric) # raises an assertion error if two objects are not equal\n",
    "print(equal_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this interpolated metric, we can update the grid object with `set_metrics`. Take note at this point that if you just want to use the built-in grid-aware operations from xgcm such as `average`, `integrate` and `cumint`, they already use `get_metric` internally. There's no need to update the metrics through `set_metrics`, this is just to show how this method can give you a level of flexibility when you are experimenting with getting the right metrics for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Assign areacello_uo as a coordinate of subset so that you can assign it as a metric \n",
    "subset = ds_subset.assign_coords(areacello_uo=areacello_uo.reset_coords(drop=True).fillna(0)) # fill missing values with 0\n",
    "\n",
    "# Step 2: Create an updated grid object\n",
    "grid_updated = Grid(\n",
    "    subset,\n",
    "    coords={\n",
    "        'X':{'center':'x', 'right':'x_c'},\n",
    "        'Y':{'center':'y', 'right':'y_c'},\n",
    "        'Z':{'center':'lev'},\n",
    "    },\n",
    "    periodic=False,\n",
    "    boundary='extend',\n",
    ")\n",
    "\n",
    "# Step 3a: Assign areacello_uo as a metric. \n",
    "grid_updated.set_metrics(('X','Y'),'areacello_uo')\n",
    "\n",
    "# Step 3b: Take note that with set_metrics you can assign multiple metrics on the same axes to your dataset as long as they have different dimensions.\n",
    "grid_updated.set_metrics(('X','Y'),'areacello')\n",
    "\n",
    "# Step 4: Double check if the metrics were assigned\n",
    "grid_updated._metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm that we get the same temperature and u-velocity time series with this updated grid object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev_layer=0\n",
    "time_start='2012-01-01'\n",
    "time_end='2014-12-31'\n",
    "\n",
    "mean_sst_updated = grid_updated.average(subset.thetao.isel(lev=lev_layer).sel(time=slice(time_start,time_end)).squeeze(),['X','Y'])\n",
    "diff_sst = mean_sst-mean_sst_updated\n",
    "diff_sst.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev_layer=0\n",
    "time_start='2012-01-01'\n",
    "time_end='2014-12-31'\n",
    "\n",
    "mean_uo_updated = grid_updated.average(subset.uo.isel(lev=lev_layer).sel(time=slice(time_start,time_end)).squeeze(),['X','Y'])\n",
    "diff_uo = mean_uo-mean_uo_updated\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([1,1,1,1])\n",
    "ax.plot(diff_uo)\n",
    "ax.set_ylim(-1,1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42143b80c7e25dd10a9414519f35ae1b958f66e22d4c0d866543ab216d08a4c6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
